{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428cc3bb",
   "metadata": {},
   "source": [
    "# Grabing the montly data on drug seizures published by the US Customs and Border Patrol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b0a431",
   "metadata": {},
   "source": [
    "The US CBP update a [dashboard](https://www.cbp.gov/newsroom/stats/drug-seizure-statistics) monthly and also provide CSVs of the data [here](https://www.cbp.gov/document/stats/nationwide-drug-seizures). The scaper in this script is going to go through the following steps:\n",
    "1. grab the HTML of the website with the CSV files\n",
    "2. grab the date of the latest CSV\n",
    "3. compare the date from step 2 to the date of the most recent dataset we have\n",
    "4. if the date from step 2 equals the date of our most recent data, the script stops, if it is more recent, we download the lastest CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d2437",
   "metadata": {},
   "source": [
    "Before actually writing our code, we need to import the libraries that we're going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "931da7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dc6526",
   "metadata": {},
   "source": [
    "## 1. grab the HTML of the website with the CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ceeef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the URL\n",
    "url = \"http://www.cbp.gov/document/stats/nationwide-drug-seizures\"\n",
    "\n",
    "# Make the website think we're a normal person browsing, not a bot\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36',\n",
    "}\n",
    "\n",
    "# Get the HTML from the URL\n",
    "response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d7082",
   "metadata": {},
   "source": [
    "This next cell is options and will be deleted before the code goes into production. If the last step is successful, the computer returns the status 200. So it we get that status, the notebook prints the code so we can see it, and it not, it tells us we have an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01e475c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page downloaded sucessfully\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    #print(response.text)  \n",
    "    print('Page downloaded sucessfully')\n",
    "else:\n",
    "    print(f'Request failed with status code: {response.status_code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646769a",
   "metadata": {},
   "source": [
    "## 2. grab the date of the latest CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00f997e",
   "metadata": {},
   "source": [
    "This code is going to take the HTML we just grabbed, as select the first row of a table on the page. The way the HTML is structred[1], \n",
    "\n",
    "[1] As of my writing of this code. Websites are often updated, and if the CBP change their website, this code will have to be modified accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55aaf165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-08\n"
     ]
    }
   ],
   "source": [
    "# Parse the content with BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all <td> tags\n",
    "table_tags = soup.find_all('td')[2]\n",
    "\n",
    "# Strip out the HTML\n",
    "latest_date_str = re.sub(r'\\s+', '', re.sub('</td>', '', re.sub('<td.*>', '', str(table_tags))))\n",
    "\n",
    "latest_date = datetime.strptime(latest_date_str, \"%m/%d/%Y\").date()\n",
    "print(latest_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc636d61",
   "metadata": {},
   "source": [
    "## 3. if the date from step 2 equals the date of our most recent data, the script stops, if it is more recent, we download the lastest CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba95df4",
   "metadata": {},
   "source": [
    "In step 4, we compare two dates and then best on the results, call different functions. In order for that to work, we need to have the functions already defined. So here, we'll define all the options, then we'll run the comparison and the program will execute whichever function is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b311ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.cbp.gov\"\n",
    "def get_dataset():\n",
    "    link_tags = soup.find('tbody')\n",
    "    link_stub = link_tags.find('a').get('href')\n",
    "\n",
    "    full_url = base_url + link_stub\n",
    "    filename = \"data/cbp_data_\" + str(latest_date) + \".csv\"\n",
    "\n",
    "    query_parameters = {\"downloadformat\": \"csv\"}\n",
    "    data_response = requests.get(full_url, params=query_parameters)\n",
    "    if data_response.status_code == 200:\n",
    "        with open(filename, mode=\"wb\") as file:\n",
    "            file.write(data_response.content)\n",
    "    else:\n",
    "        raise ValueError(f'Request failed with status code: {data_response.status_code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb021c9",
   "metadata": {},
   "source": [
    "## 4. compare the date from step 2 to the date of the most recent dataset we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a00ab6-2c9d-4fdd-83ad-1a6c0d4ce79b",
   "metadata": {},
   "source": [
    "This next cell looks at all the files saved in the `data` folder. It strips the date from the file names and assigns the most recent date to the `current_date` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc726ced-aaad-481c-956c-a2eb6fb9c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(os.listdir('data/')) > 0:\n",
    "    matches = [file for file in os.listdir('data/') if \"cbp_data_\" in file]\n",
    "    date_str = ([datetime.strptime(match.replace('cbp_data_', '')\n",
    "                                   .replace('.csv', ''), \"%Y-%m-%d\")\n",
    "                 .date() for match in matches])\n",
    "    current_date = max(date_str)\n",
    "else:\n",
    "    raise ValueError('Error:\\nNo files in the \"data/\" directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321c9f26-07ff-4cf7-bef9-e81bc992ba10",
   "metadata": {},
   "source": [
    "The function `compare_dates` is going to take the variable `current_date` and compare it to the variable `latest_date` we created in step 2. When `compare_dates` is earlier than `current_date`, it will call the `get_dataset()` function to we defined in step 3. If `current_date` is equal to the `latest_date`, that means we already have the latest dataset and the program stops. If the `current_date` is greater than the `latest_date`, that means there's and error or the CBP has taken down some of their data. This needs to be investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7793971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is already up to date\n"
     ]
    }
   ],
   "source": [
    "def compare_dates(latest_date):\n",
    "    if current_date < latest_date:\n",
    "        get_dataset()\n",
    "    elif current_date == latest_date:\n",
    "        print(\"Dataset is already up to date\")\n",
    "    else:\n",
    "        raise ValueError(\"Error:\\nSomething is wrong. The current dataset\\nseems to be more recent than the most\\nrecent data. You should investigate whether\\nthe site structure has changed or a dataset\\nwas removed.\")\n",
    "        \n",
    "compare_dates(latest_date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cbp-venv",
   "language": "python",
   "name": "cbp-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
